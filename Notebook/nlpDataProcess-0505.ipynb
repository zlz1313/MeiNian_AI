{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from math import isnan\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Output/0505/train_data_tezheng1.csv', encoding='utf-8')\n",
    "test = pd.read_csv('../Output/0505/test_data_tezheng1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38199, 399)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将训练集中指标为NAN的舍弃掉\n",
    "\n",
    "train = train[~train.收缩压.isnull()]\n",
    "train = train[~train.舒张压.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38192, 399)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cols = list(train.describe().columns[5:])   # 纯数字+NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_cols = ['vid','收缩压', '舒张压', '血清甘油三酯', '血清高密度脂蛋白', '血清低密度脂蛋白']  # vid和指标字段\n",
    "digit_cols1 = ['1814', '190', '191', '2403', '2404', '2405']                                    # BMI指标和数字（含未查等特殊）\n",
    "# digit_cols2 = ['10004','10002','1115','1117','1815','183','1850','192','193','2174','314']      # 纯数字型 （float+str）\n",
    "wenben_cols = ['0409', '0434', 'B701','A801','A705', '2302', '0114','3401','1001','0102','A202',\n",
    "               '0403','0441','0131','0912','1316','1402','0978','0954']                        # 文本\n",
    "emu_cols = ['3190', '3191', '3192', '3195', '3196','3197','3430',\n",
    "            '3189','3194','3485','3486','360']                              # 枚举型\n",
    "num_and_wenben_cols = ['3193','1840','A701','A703', '0424']                                          # 数字型 （含>= 阴性等特殊）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "# 查找混合型字段\n",
    "# 如 >100次/分,窦性心动过速    ------简单混合型\n",
    "digit_cols2 = []\n",
    "exist_digit_cols = main_cols + digit_cols1 + num_and_wenben_cols\n",
    "p = re.compile('\\d+\\.?\\d*')\n",
    "r = train.shape[0]\n",
    "for c in train.columns:\n",
    "    nulls = train[c].isnull().sum()\n",
    "    a = train[c].apply(lambda x: 1 if len(p.findall(str(x))) != 0 else 0).sum()\n",
    "    if (a+nulls) > r*0.9 and a > r*0.08 and c not in exist_digit_cols:\n",
    "        digit_cols2.append(c)\n",
    "print (len(digit_cols2)) # 0.95 0.1: 127     0.9 0.05: 207   0.9 0.08 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# 枚举类型在10-30之间的字段\n",
    "emu_columns = []\n",
    "exist_emu_cols = digit_cols2 + emu_cols + wenben_cols + ['0125','0440','0973','0981','1304','3207','3399','3402','30007']\n",
    "for c in train.columns:\n",
    "    types = len(train[c].unique())\n",
    "    if types<30 and types >10 and c not in exist_emu_cols:\n",
    "        emu_columns.append(c)\n",
    "\n",
    "print (len(emu_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_cols = main_cols + num_cols + digit_cols1 + wenben_cols + emu_cols + num_and_wenben_cols + digit_cols2 + emu_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = train[[c for c in train.columns if c in select_cols]]\n",
    "test1 = test[[c for c in test.columns if c in select_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 寻找某些特定指标相关的疾病涉及字段\n",
    "# search_cols = []\n",
    "# for c in train.columns:\n",
    "#     a = train[c].apply(lambda x: 1 if '甲亢' in str(x) else 0).sum()\n",
    "#     if a > 100:\n",
    "#         search_cols.append(c)\n",
    "# search_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (train['30007'].unique())\n",
    "# print (len(train['30007'].unique()))\n",
    "# print (train['30007'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eye_labels = ['exit','未见明显异常','不肿大','无','nan','未查','未见异','未触及','弃检','弃查','未见明显异常,建议b超检查','眼底弃查']\n",
    "# test['1402'].apply(lambda x: str(x) if  '未见明显异常' not in str(x) and '不正常' in str(x) and '未见异常' not in str(x) else 0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本字段处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heartModify(x):\n",
    "    x = str(x)\n",
    "    if '心界扩大' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def hasOperate(x):\n",
    "    x = str(x)\n",
    "    if '开颅术' in x:\n",
    "        return 1\n",
    "    elif '子宫' in x or '卵巢' in x:\n",
    "        return 2\n",
    "    elif '甲状腺' in x:\n",
    "        return 3\n",
    "    elif '心脏' in x:\n",
    "        return 4\n",
    "    return 0\n",
    "    \n",
    "\n",
    "#0403 0441 0131\n",
    "def processGanyouRelateFea(data):\n",
    "    train = data.copy()\n",
    "    train['0403'] = train['0403'].apply(heartModify)\n",
    "    train['0441'] = train['0441'].apply(hasOperate)\n",
    "    train['0131'] = train['0131'].apply(lambda x: 1 if '未见明显异常' not in str(x) else 0)\n",
    "    \n",
    "    normal_label = ['exit','未见明显异常','不肿大','无','nan','未查','未见异','未触及','弃检','弃查','未见明显异常,建议b超检查','眼底弃查']\n",
    "    train['0912'] = train['0912'].apply(lambda x: 1 if  str(x) not in normal_label and '未见异常' not in str(x) else 0)\n",
    "    train['0978_jiazhuangxian'] = train['0978'].apply(lambda x: 1 if  '甲状腺' in str(x) else 0)\n",
    "    train['0954_jiazhuangxian'] = train['0954'].apply(lambda x: 1 if  '甲状腺' in str(x) else 0)\n",
    "    train['1316'] = train['1316'].apply(lambda x: 1 if  '正常' not in str(x) and '未见异常' not in str(x) and str(x) not in normal_label else 0)\n",
    "    train['1402'] = train['1402'].apply(lambda x: 1 if  '未见明显异常' not in str(x) and '正常' in str(x) and '未见异常' not in str(x) else 0)\n",
    "    \n",
    "    train = train.drop(['0978','0954'], axis=1)\n",
    "    return train\n",
    "\n",
    "train2 = processGanyouRelateFea(train1)\n",
    "test2 = processGanyouRelateFea(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_Bchao(x):\n",
    "    x = str(x)\n",
    "    if '绝经' in x:\n",
    "        return 0\n",
    "    if '高血压' in x:\n",
    "        return 1\n",
    "    if '脂肪肝' in x:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "def processWenBen(data):\n",
    "    train = data.copy()\n",
    "    cols = ['0102','A202']\n",
    "    for col in cols:\n",
    "        train[col+'bchao'] = train[col].apply(label_Bchao)\n",
    "    return train.drop(cols, axis=1)\n",
    "\n",
    "test2 = processWenBen(test2)\n",
    "train2 = processWenBen(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xindiantu(x):\n",
    "    x = str(x)\n",
    "    if x == 'nan' or '正常心电图' in x:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def process1001(data):\n",
    "    train = data.copy()\n",
    "    train['1001_xindiantu'] = train['1001'].apply(xindiantu)\n",
    "    return train.drop(['1001'], axis=1)\n",
    "\n",
    "test2 = process1001(test2)\n",
    "train2 = process1001(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process114_2302(data):\n",
    "    train = data.copy()\n",
    "    train['0114_normal'] = (train['0114'].fillna(-1)).apply(lambda x: int('胆囊大小、形态正常' in  x) if x!= -1 else x)\n",
    "    train = train.drop(['0114'], axis=1)\n",
    "\n",
    "    train['2302_jiankang'] = (train['2302'].fillna(-1)).apply(lambda x: int('健康' in  x) if x!= -1 else x)\n",
    "    train = train.drop(['2302'], axis=1)\n",
    "    return train\n",
    "\n",
    "test2 = process114_2302(test2)\n",
    "train2 = process114_2302(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process409_434(data):\n",
    "    train = data.copy()\n",
    "    cols = []\n",
    "    for c in ['0409', '0434']:\n",
    "        train[c] = train[c].astype('str')\n",
    "        if c == '0434':\n",
    "            train[c+'_smoke'] = train[c].apply(lambda x: '吸烟' in  x).astype('int')\n",
    "            train[c+'_gaoxueya'] = train[c].apply(lambda x: '高血压' in  x or '血压偏高' in x).astype('int')\n",
    "            train[c+'_gaoxuezhi'] = train[c].apply(lambda x: '血脂偏高' in  x ).astype('int')\n",
    "            train[c+'_tangniaobing'] = train[c].apply(lambda x: '糖尿病' in  x ).astype('int')\n",
    "            train[c+'_niaosuan'] = train[c].apply(lambda x: '尿酸偏高' in  x ).astype('int')\n",
    "            train[c+'_gan'] = train[c].apply(lambda x: '肝' in  x).astype('int')\n",
    "            train[c+'_zhifangan'] = train[c].apply(lambda x: '脂肪肝' in  x).astype('int')\n",
    "            train[c+'_feipang'] = train[c].apply(lambda x: '肥胖' in  x).astype('int')\n",
    "            train[c+'_heart'] = train[c].apply(lambda x: '心' in  x or '冠状动脉' in x).astype('int')\n",
    "            train[c+'_pregnancy'] = train[c].apply(lambda x: '孕' in  x and '宫外孕术后' not in x).astype('int')\n",
    "            train[c+'_yanzheng'] = train[c].apply(lambda x: '炎' in  x).astype('int')\n",
    "            train[c+'_jzxkangjin'] = train[c].apply(lambda x: '甲亢' in  x or '甲状腺功能亢进'in x).astype('int')\n",
    "            train[c+'_jzxjt'] = train[c].apply(lambda x: '甲状腺功能减退' in  x).astype('int')\n",
    "        else:\n",
    "            train[c+'_free'] = train[c].apply(lambda x: '未发现明显异常' in  x or '未见异常' in x).astype('int')\n",
    "            train[c+'_yanzheng'] = train[c].apply(lambda x: '炎' in  x).astype('int')\n",
    "            train[c+'_niaosuan'] = train[c].apply(lambda x: '高尿酸' in  x ).astype('int')\n",
    "            train[c+'_gaoxuezhi'] = train[c].apply(lambda x: '血脂偏高' in  x ).astype('int')\n",
    "            train[c+'_gaoxuetang'] = train[c].apply(lambda x: '血糖偏高' in  x ).astype('int')\n",
    "            train[c+'_gaoxueya'] = train[c].apply(lambda x: '高血压' in  x or '血压偏高' in x).astype('int')\n",
    "            train[c+'_gaoxuezhi'] = train[c].apply(lambda x: '血脂偏高' in  x or '高血脂' in x).astype('int')\n",
    "            train[c+'_zhifangan'] = train[c].apply(lambda x: '脂肪肝' in  x).astype('int')\n",
    "            train[c+'_beatslow'] = train[c].apply(lambda x: '心动过缓' in  x).astype('int')\n",
    "            train[c+'_beatfast'] = train[c].apply(lambda x: '心动过速' in  x).astype('int')\n",
    "            train[c+'_beatunregular'] = train[c].apply(lambda x: '心律不齐' in  x).astype('int')\n",
    "            train[c+'_beatfre'] = train[c].apply(lambda x: '偶发早搏' in  x).astype('int')\n",
    "            train[c+'_heartok'] = train[c].apply(lambda x: '心率正常' in  x).astype('int')\n",
    "            train[c+'_heartnoise'] = train[c].apply(lambda x: '心脏杂音' in  x or '心音' in x).astype('int')\n",
    "            train[c+'_tangniaobing'] = train[c].apply(lambda x: '糖尿病' in  x ).astype('int')\n",
    "            train[c+'_gan'] = train[c].apply(lambda x: '肝' in  x).astype('int')\n",
    "            train[c+'_heart'] = train[c].apply(lambda x: '心肌' in  x or '心脏' in x).astype('int')\n",
    "            train[c+'_jzxkangjin'] = train[c].apply(lambda x: '甲亢' in  x or '甲状腺功能亢进'in x).astype('int')\n",
    "            train[c+'_jzxjt'] = train[c].apply(lambda x: '甲状腺功能减退' in  x).astype('int')\n",
    "            train[c+'_tangniaobing'] = train[c].apply(lambda x: '糖尿病' in  x ).astype('int')\n",
    "\n",
    "    return train.drop(['0409','0434'], axis=1)\n",
    "\n",
    "test2 = process409_434(test2)\n",
    "train2 = process409_434(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeature3401(x):\n",
    "    x = str(x)\n",
    "    if x == 'nan' or ('未见明显异常' in x and '检查' not in x and '复查'not in x):\n",
    "        return 0\n",
    "    elif '退变' in x :\n",
    "        return 2\n",
    "    elif '未见明显异常' in x and ('检查'  in x or '复查' in x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def process3401(data):\n",
    "    train = data.copy()\n",
    "    train['3401_ct'] = train['3401'].apply(getFeature3401)\n",
    "    return train.drop(['3401'], axis=1)\n",
    "\n",
    "test2 = process3401(test2)\n",
    "train2 = process3401(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processAB(data):\n",
    "    train = data.copy()\n",
    "    train['A705_label'] = (train['A705'].fillna(-1)).apply(lambda x: int('数字化肝超未发现明显异常' in  x) if x != -1 else x)\n",
    "    train['A801_label'] = (train['A801'].fillna(-1)).apply(lambda x: int('脑血流图未发现明显异常' in  x) if x != -1 else x)\n",
    "    train['B701_label'] = (train['B701'].fillna(-1)).apply(lambda x: int('糖尿病或糖尿病前期风险较小' in  x) if x != -1 else x)\n",
    "    train = train.drop(['B701','A801','A705'], axis=1)\n",
    "    return train\n",
    "\n",
    "test3 = processAB(test2)\n",
    "train3 = processAB(train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3402基本无异常\n",
    "\n",
    "A601大部分详见纸质报告\n",
    "\n",
    "数字为主： A701、A703、3193、1840  \n",
    "\n",
    "性别标签: 0120 0121 0125 0130"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 枚举类型字段处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "枚举型变量：\n",
    "\n",
    "'3190', '3191', '3192', '3195', '3196','3197'   ：阴阳性，+-\n",
    "\n",
    "混合型变量：\n",
    "\n",
    " '0424','1840','3193'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 枚举型'3190', '3191', '3192', '3195', '3196','3197',3430\n",
    "def emuFeature(x):\n",
    "    good_labels = ['nan','阴性','未做','normal','正常']\n",
    "    nor_labels = ['+-','未见']\n",
    "    bad_labels = ['阳性','阳性(+)','阳性(1+)','阳性3+']\n",
    "    x = str(x)\n",
    "    if x in nor_labels or '+-' in x:\n",
    "        return 1\n",
    "    elif x in good_labels or '-' in x:\n",
    "        return 0\n",
    "    elif x in bad_labels or '+' in x:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def processEmu(data):\n",
    "    train = data.copy()\n",
    "    for col in emu_cols:\n",
    "        train[col] =  train[col].apply(emuFeature)\n",
    "        \n",
    "    return train\n",
    "\n",
    "test3 = processEmu(test3)\n",
    "train3 = processEmu(train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numAndWenben(x):\n",
    "    x = str(x)\n",
    "    if x == 'nan' or x =='阴性' or x=='-' or x=='未做':\n",
    "        return np.nan\n",
    "    else:\n",
    "        p = re.compile('\\d+\\.?\\d*')\n",
    "        return p.findall(x)[0]\n",
    "\n",
    "def processNumAndWenben(train):\n",
    "    data = train.copy()\n",
    "    cols = ['3193','1840','A701','A703']\n",
    "    for c in cols:\n",
    "        data[c] = data[c].apply(numAndWenben).astype('float').fillna(0)\n",
    "    return data\n",
    "\n",
    "test3 = processNumAndWenben(test3)\n",
    "train3 = processNumAndWenben(train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processEmuWenFeature(data):\n",
    "    train = data.copy()\n",
    "    emu_good_labels = ['nan', '未见异常','无异常','正常','未闻及异常','有力',\n",
    "                   '弃查','未触及','未 触及','未及','不大','exit','未见明显异常',\n",
    "                  '视不见','未查','无压痛','无','未见异','纹理清晰']\n",
    "    for c in emu_columns:\n",
    "        train[c] = train[c].apply(lambda x: 0 if '无' in str(x) or '未' in str(x) or str(x) in emu_good_labels else 1)\n",
    "        \n",
    "    return train\n",
    "\n",
    "test4 = processEmuWenFeature(test3)\n",
    "train4 = processEmuWenFeature(train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数值型字段处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_heart_rate(x):\n",
    "    import re\n",
    "    result = re.findall(r\"\\d+\",x)\n",
    "    if result != []:\n",
    "        return result[0]\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def is_heart_slow(x):\n",
    "    return ('过缓' in x) or ('<' in x )or (int(get_heart_rate(x))<60 and int(get_heart_rate(x))>1)\n",
    "\n",
    "def is_heart_fast(x):\n",
    "    return ('过速' in x) or ('>' in x )or (int(get_heart_rate(x))>100 ) \n",
    "\n",
    "def is_heart_normal(x):\n",
    "    return (int(get_heart_rate(x))>60 and int(get_heart_rate(x))<100) or ('正常' in x) or ('未见' in x)\n",
    "\n",
    "def process424(data):\n",
    "    train = data.copy()\n",
    "    train['0424'] = train['0424'].astype('str')\n",
    "    train['424_heart_rate'] = (train['0424'].apply(lambda x: get_heart_rate(x))).astype('int')\n",
    "    train['424_heart_slow'] = train['0424'].apply(lambda x: is_heart_slow(x)).astype('int')\n",
    "    train['424_heart_fast'] = train['0424'].apply(lambda x: is_heart_fast(x)).astype('int')\n",
    "    train['424_heart_normal'] = train['0424'].apply(lambda x: is_heart_normal(x)).astype('int')\n",
    "\n",
    "    return train.drop(['0424'], axis=1)\n",
    "\n",
    "test4 = process424(test4)\n",
    "train4 = process424(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modifyYiChang(x):\n",
    "    if ';' in str(x):\n",
    "        spices = x.split(';')\n",
    "        if spices.count('nan') == 2 or spices.count('未查') == 2 or spices.count('弃查') == 2:\n",
    "            return np.nan\n",
    "        elif spices.count('nan') == 1:\n",
    "            return spices[1-spices.index('nan')]\n",
    "        elif spices.count('未查') == 1:\n",
    "            return spices[1-spices.index('未查')]\n",
    "        elif spices.count('弃查') == 1:\n",
    "            return spices[1-spices.index('弃查')]\n",
    "        else :\n",
    "            return spices[0]\n",
    "    elif '查' in str(x):\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "def process4(data):\n",
    "    train = data.copy()\n",
    "    for col in digit_cols1:\n",
    "        train[col] = train[col].apply(modifyYiChang).astype('float').fillna(0)\n",
    "    return train\n",
    "\n",
    "test4 = process4(test4)\n",
    "train4 = process4(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def searchDigitRe(x):\n",
    "    x = str(x)\n",
    "    if x == 'nan':\n",
    "        return 0\n",
    "    else:\n",
    "        try:\n",
    "            p = re.compile('\\d+\\.?\\d*')\n",
    "            return p.findall(x)[0]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "def processPureDigit(data):\n",
    "    train = data.copy()\n",
    "    for col in num_cols:\n",
    "            train[col] = train[col].apply(searchDigitRe).astype('float').fillna(0)\n",
    "    return train\n",
    "\n",
    "test4 = processPureDigit(test4)\n",
    "train4 = processPureDigit(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDigit2(data):\n",
    "    train = data.copy()\n",
    "    for col in digit_cols2:\n",
    "        train[col] = train[col].apply(searchDigitRe).astype('float').fillna(0)\n",
    "    return train\n",
    "\n",
    "test_end = processDigit2(test4)\n",
    "train_end = processDigit2(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_end.to_csv('../Output/0505/train_data_tezheng2.csv', index=False, encoding='utf-8')\n",
    "test_end.to_csv('../Output/0505/test_data_tezheng2.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38192, 282)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_end.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = train_end\n",
    "test1 = test_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from math import isnan\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "train1 = pd.read_csv('../Output/0505/train_data_tezheng2.csv', encoding='utf-8')\n",
    "test1 = pd.read_csv('../Output/0505/test_data_tezheng2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../Output/0505/train_data_tezheng1.csv', encoding='utf-8')\n",
    "num_cols = list(train.describe().columns[5:])   # 纯数字+NAN\n",
    "\n",
    "main_cols = ['vid','收缩压', '舒张压', '血清甘油三酯', '血清高密度脂蛋白', '血清低密度脂蛋白']  # vid和指标字段\n",
    "digit_cols1 = ['1814', '190', '191', '2403', '2404', '2405']                                    # BMI指标和数字（含未查等特殊）\n",
    "# digit_cols2 = ['10004','10002','1115','1117','1815','183','1850','192','193','2174','314']      # 纯数字型 （float+str）\n",
    "wenben_cols = ['0409', '0434', 'B701','A801','A705', '2302', '0114','3401','1001','0102','A202',\n",
    "               '0403','0441','0131','0912','1316','1402','0978','0954']                        # 文本\n",
    "emu_cols = ['3190', '3191', '3192', '3195', '3196','3197','3430',\n",
    "            '3189','3194','3485','3486','360']                              # 枚举型\n",
    "num_and_wenben_cols = ['3193','1840','A701','A703', '0424']   \n",
    "\n",
    "# 查找混合型字段\n",
    "# 如 >100次/分,窦性心动过速    ------简单混合型\n",
    "digit_cols2 = []\n",
    "exist_digit_cols = main_cols + digit_cols1 + num_and_wenben_cols\n",
    "p = re.compile('\\d+\\.?\\d*')\n",
    "r = train.shape[0]\n",
    "for c in train.columns:\n",
    "    nulls = train[c].isnull().sum()\n",
    "    a = train[c].apply(lambda x: 1 if len(p.findall(str(x))) != 0 else 0).sum()\n",
    "    if (a+nulls) > r*0.9 and a > r*0.05 and c not in exist_digit_cols:\n",
    "        digit_cols2.append(c)\n",
    "print (len(digit_cols2)) # 0.95 0.1: 127     0.9 0.05: 207\n",
    "\n",
    "# 枚举类型在10-30之间的字段\n",
    "emu_columns = []\n",
    "exist_emu_cols = digit_cols2 + emu_cols + wenben_cols + ['0125','0440','0973','0981','1304','3207','3399','3402','30007']\n",
    "for c in train.columns:\n",
    "    types = len(train[c].unique())\n",
    "    if types<30 and types >10 and c not in exist_emu_cols:\n",
    "        emu_columns.append(c)\n",
    "\n",
    "print (len(emu_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38192, 282)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 比赛要求自定义log_loss\n",
    "def cal_logloss(label, pre_label):\n",
    "    rows = len(label)\n",
    "    log_sum = sum((np.log(pre_label+1) - np.log(label+1)) ** 2)\n",
    "    return log_sum / rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit_cols = num_cols + ['424_heart_rate','1814', '190', '191', '2403', '2404', '2405'] + digit_cols2 + ['3193','1840','A701','A703']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "rows = train1.shape[0]\n",
    "data = train1.append(test1)\n",
    "data[['424_heart_rate','1814', '190', '191', '2403', '2404', '2405']] = data[['424_heart_rate','1814', '190', '191', '2403', '2404', '2405']].fillna(0)\n",
    "for c in digit_cols:\n",
    "    data[c] = MinMaxScaler().fit_transform(data[c].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38192, 282)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = data[:rows]\n",
    "test1 = data[rows:]\n",
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shousuoya_label = train1.pop('收缩压')\n",
    "shuzhangya_label = train1.pop('舒张压')\n",
    "highzhidanbai_label = train1.pop('血清高密度脂蛋白')\n",
    "ganyou_label = train1.pop('血清甘油三酯')\n",
    "lowzhidanbai_label = train1.pop('血清低密度脂蛋白')\n",
    "\n",
    "train1 = train1.drop('vid', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1.pop('收缩压')\n",
    "test1.pop('舒张压')\n",
    "test1.pop('血清高密度脂蛋白')\n",
    "test1.pop('血清甘油三酯')\n",
    "test1.pop('血清低密度脂蛋白')\n",
    "\n",
    "test1_vid = test1.pop('vid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_table = {'收缩压':shousuoya_label,\n",
    "              '舒张压':shuzhangya_label,\n",
    "              '血清甘油三酯':ganyou_label,\n",
    "              '血清高密度脂蛋白':highzhidanbai_label,\n",
    "              '血清低密度脂蛋白':lowzhidanbai_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_score = {}\n",
    "test_label = {}\n",
    "test_size_dict = {'收缩压':0.05,\n",
    "                  '舒张压':0.01,\n",
    "                  '血清甘油三酯':0.2,\n",
    "                  '血清高密度脂蛋白':0.2,\n",
    "                  '血清低密度脂蛋白':0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emu_columns   \n",
    "emu_cols \n",
    "\n",
    "digit_cols1 = ['1814', '190', '191', '2403', '2404', '2405']\n",
    "\n",
    "digit_cols2 = ['10004','10002','1115','1117','1815','183','1850','192','193','2174','314']\n",
    "\n",
    "wenben_cols = ['0409', '0434', 'B701','A801','A705', '2302', '0114','3401','1001','0102','A202',\n",
    "               '0403','0441','0131','0912','1316','1402','0978','0954']\n",
    "               \n",
    "emu_cols = ['3190', '3191', '3192', '3195', '3196','3197','3430',\n",
    "            '3189','3194','3485','3486','360']\n",
    "            \n",
    "num_and_wenben_cols = ['3193','1840','A701','A703', '0424'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=60, \n",
    "                         learning_rate=0.1, \n",
    "                         num_leaves=63, \n",
    "                         min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032630458206609834"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xunlian(data, train_table=train_table):\n",
    "    train = data.copy()\n",
    "    log_score = 0\n",
    "    for key in train_table.keys():\n",
    "        X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=0.2, random_state=0)\n",
    "        LGBM.fit(X_train, y_train)\n",
    "        preLabel = LGBM.predict(X_test)\n",
    "        log_cur = cal_logloss(y_test, preLabel)\n",
    "        log_score += log_cur\n",
    "        log_avg = log_score / 5\n",
    "    return log_avg\n",
    "\n",
    "# train2 = train1[[c for c in train1.columns if c not in select_cols_fanwei]]\n",
    "xunlian(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0326304582066\n",
      "0409:0.0326304582066\n",
      "0434:0.0326304582066\n",
      "B701:0.0326304582066\n",
      "A801:0.0326304582066\n",
      "A705:0.0326304582066\n",
      "2302:0.0326304582066\n",
      "0114:0.0326304582066\n",
      "3401:0.0326304582066\n",
      "1001:0.0326304582066\n",
      "0102:0.0326304582066\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-010e5b1d90dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcurrent_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mlog_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxunlian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlog_avg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcurrent_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-d893301dfb0c>\u001b[0m in \u001b[0;36mxunlian\u001b[1;34m(data, train_table)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mLGBM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mpreLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlog_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_logloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    616\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1302\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1303\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# change non-float data to float data, need to copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "select_cols_fanwei = wenben_cols + emu_cols + num_and_wenben_cols + digit_cols1 + ['0441','0978_jiazhuangxian','0131','1316'] + emu_columns\n",
    "current_cols = [c for c in train1.columns if c not in select_cols_fanwei]\n",
    "select_cols = []\n",
    "best_score = xunlian(train1[[c for c in current_cols]])\n",
    "print (best_score)\n",
    "for row in select_cols_fanwei:\n",
    "    current_cols.append(row)\n",
    "    train2 = train1[[c for c in train1.columns if c in current_cols]]\n",
    "    log_avg = xunlian(train2)\n",
    "    if best_score <= log_avg:\n",
    "        current_cols.pop()\n",
    "    else:\n",
    "        print (str(row) + ':'+ str(log_avg))\n",
    "        best_score = log_avg\n",
    "        select_cols.append(row)\n",
    "            \n",
    "print (select_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0146691616043\n",
      "0.0186938486299\n",
      "0.0776254080108\n",
      "0.0126093343976\n",
      "0.0342919036802\n",
      "0.0315779312646\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316'] + num_and_wenben_cols + emu_columns +['0403','0441','0131','0912','1316','1402','0978','0954']\n",
    "log_score = 0\n",
    "test_label = {}\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "for key in train_table.keys():\n",
    "    X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=0.2, random_state=0)\n",
    "    LGBM.fit(X_train, y_train)\n",
    "    preLabel = LGBM.predict(X_test)\n",
    "    log_cur = cal_logloss(y_test, preLabel)\n",
    "    log_score += log_cur\n",
    "#     preLabel = LGBM.predict(test2)\n",
    "#     test_label[key] = preLabel\n",
    "    print (log_cur)\n",
    "print (log_score / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateResult(vid, shousuoya_label, shuzhangya_label, ganyou_label, highzhidanbai_label, lowzhidanbai_label, filename='../Output/result0505.csv'):\n",
    "    result = pd.DataFrame({'vid':vid})\n",
    "    result['收缩压'] = shousuoya_label\n",
    "    result['舒张压'] = shuzhangya_label\n",
    "    result['血清甘油三酯'] = ganyou_label\n",
    "    result['血清高密度脂蛋白'] = highzhidanbai_label\n",
    "    result['血清低密度脂蛋白'] = lowzhidanbai_label\n",
    "    result.to_csv(filename, index=False, header=False ,line_terminator='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generateResult(test1_vid, test_label['收缩压'], test_label['舒张压'], \n",
    "               test_label['血清甘油三酯'], test_label['血清高密度脂蛋白'], \n",
    "               test_label['血清低密度脂蛋白'], filename='../Output/new_result312.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 收缩压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0138741132151\n"
     ]
    }
   ],
   "source": [
    "key = '收缩压'\n",
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316'] + num_and_wenben_cols\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "\n",
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=600, \n",
    "                         learning_rate=0.01, \n",
    "                         num_leaves=63, \n",
    "                         min_samples_split=2,\n",
    "                         subsample=0.7)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=test_size_dict[key], random_state=1)\n",
    "LGBM.fit(X_train, y_train)\n",
    "preLabel = LGBM.predict(X_test)\n",
    "log_cur = cal_logloss(y_test, preLabel)\n",
    "log_score.setdefault(key, 0.0)\n",
    "log_score[key] = log_cur\n",
    "preLabel = LGBM.predict(test2)\n",
    "test_label[key] = preLabel\n",
    "print (log_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 舒张压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0139016007101\n"
     ]
    }
   ],
   "source": [
    "key = '舒张压'\n",
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316']\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "\n",
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=600, \n",
    "                         learning_rate=0.01, \n",
    "                         num_leaves=63, \n",
    "                         min_samples_split=2,\n",
    "                         subsample=0.7)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=test_size_dict[key], random_state=47)\n",
    "LGBM.fit(X_train, y_train)\n",
    "preLabel = LGBM.predict(X_test)\n",
    "log_cur = cal_logloss(y_test, preLabel)\n",
    "\n",
    "log_score.setdefault(key, 0.0)\n",
    "log_score[key] = log_cur\n",
    "preLabel = LGBM.predict(test2)\n",
    "test_label[key] = preLabel\n",
    "print (log_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 血清甘油三酯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0751216670762\n"
     ]
    }
   ],
   "source": [
    "key = '血清甘油三酯'\n",
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316'] + num_and_wenben_cols + emu_columns\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "\n",
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=600, \n",
    "                         learning_rate=0.01, \n",
    "                         num_leaves=63,\n",
    "                         min_samples_split=2)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=test_size_dict[key], random_state=34)\n",
    "LGBM.fit(X_train, y_train)\n",
    "preLabel = LGBM.predict(X_test)\n",
    "log_cur = cal_logloss(y_test, preLabel)\n",
    "log_score.setdefault(key, 0.0)\n",
    "log_score[key] = log_cur\n",
    "preLabel = LGBM.predict(test2)\n",
    "test_label[key] = preLabel\n",
    "print (log_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 血清高密度脂蛋白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0120046143224\n"
     ]
    }
   ],
   "source": [
    "key = '血清高密度脂蛋白'\n",
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316'] + emu_cols\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "\n",
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=60, \n",
    "                         learning_rate=0.1, \n",
    "                         num_leaves=63,\n",
    "                         min_samples_split=2)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=test_size_dict[key], random_state=2)\n",
    "LGBM.fit(X_train, y_train)\n",
    "preLabel = LGBM.predict(X_test)\n",
    "log_cur = cal_logloss(y_test, preLabel)\n",
    "\n",
    "log_score.setdefault(key, 0.0)\n",
    "log_score[key] = log_cur\n",
    "preLabel = LGBM.predict(test2)\n",
    "test_label[key] = preLabel\n",
    "print (log_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 血清低密度脂蛋白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0267328307068\n"
     ]
    }
   ],
   "source": [
    "key = '血清低密度脂蛋白'\n",
    "drop_cols = ['0441','0978_jiazhuangxian','0131','1316'] + num_and_wenben_cols + emu_columns\n",
    "train2 = train1[[c for c in train1.columns if c not in drop_cols]]\n",
    "test2 = test1[[c for c in test1.columns if c not in drop_cols]]\n",
    "\n",
    "LGBM = lgb.LGBMRegressor(objective='regression_l2', \n",
    "                         max_depth=7, \n",
    "                         n_estimators=600, \n",
    "                         learning_rate=0.01, \n",
    "                         num_leaves=63,\n",
    "                         min_samples_split=2)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2, train_table[key], test_size=test_size_dict[key], random_state=13)\n",
    "LGBM.fit(X_train, y_train)\n",
    "preLabel = LGBM.predict(X_test)\n",
    "log_cur = cal_logloss(y_test, preLabel)\n",
    "\n",
    "log_score.setdefault(key, 0.0)\n",
    "log_score[key] = log_cur\n",
    "preLabel = LGBM.predict(test2)\n",
    "test_label[key] = preLabel\n",
    "print (log_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02832696520611443"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for val in log_score.values():\n",
    "    score += val\n",
    "score / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0.013874113215116947, 0.013901600710077497, 0.075121667076236825, 0.012004614322355112, 0.026732830706785761])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = {}\n",
    "for key in train_table.keys():\n",
    "    LGBM.fit(train1, train_table[key])\n",
    "    preLabel = LGBM.predict(test1)\n",
    "    test_label[key] = preLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generateResult(test1_vid, test_label['收缩压'], test_label['舒张压'], \n",
    "               test_label['血清甘油三酯'], test_label['血清高密度脂蛋白'], \n",
    "               test_label['血清低密度脂蛋白'], filename='../Output/new_result0507.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
