{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp1 = pd.read_csv(\"../data/meinian_round1_data_part1_20180408.txt\", sep=\"$\")\n",
    "dp2 = pd.read_csv(\"../data/meinian_round1_data_part2_20180408.txt\", sep=\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = dp1.append(dp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = dp.sort_values('vid').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2795\n"
     ]
    }
   ],
   "source": [
    "cols = dp['table_id'].unique()\n",
    "print (len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dp1['table_id'].unique())+len(dp2['table_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8104368, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除空格、全角转半角、全小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def DBC2SBC(ustring):\n",
    "    \"\"\"全角转半角\"\"\"\n",
    "    rstring = \"\"\n",
    "    for uchar in ustring:\n",
    "        inside_code=ord(uchar)\n",
    "        if inside_code == 12288:                              #全角空格直接转换            \n",
    "            inside_code = 32 \n",
    "        elif (inside_code >= 65281 and inside_code <= 65374): #全角字符（除空格）根据关系转化\n",
    "            inside_code -= 65248\n",
    "        rstring += chr(inside_code)\n",
    "    return rstring\n",
    "\n",
    "dp['field_results'] = dp['field_results'].apply(lambda x: str(x).strip())\n",
    "dp['field_results'] = dp['field_results'].apply(lambda x: str(x).lower())\n",
    "dp['field_results'] = dp['field_results'].apply(lambda x: DBC2SBC(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相同体检项目拼接组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dp_dup = dp.groupby(['vid', 'table_id'], as_index=False).agg('last') # 重复体检项目只取最后一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_data(data):\n",
    "    data['field_results'] = data['field_results'].astype(str)\n",
    "    if data.shape[0]>1:\n",
    "        merge_df = \";\".join(list(data['field_results']))\n",
    "    else :\n",
    "        merge_df = data['field_results'].values[0]\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------去重和组合-----------\n",
      "---------END-----------\n"
     ]
    }
   ],
   "source": [
    "print (\"---------去重和组合-----------\")\n",
    "# 区分唯一项目和重复项目\n",
    "# size()返回dataFrame的重复记录条数\n",
    "vid_tabid_group = dp.groupby(['vid','table_id']).size().reset_index()\n",
    "vid_tabid_group['new_index'] = vid_tabid_group['vid'] + '_' + vid_tabid_group['table_id']\n",
    "vid_tableid_gruop_dup = vid_tabid_group[vid_tabid_group[0]>1]['new_index']\n",
    "\n",
    "vid_tableid_gruop_dup_list = list(vid_tableid_gruop_dup)\n",
    "dp['new_index'] = dp['vid'] + '_' + dp['table_id']\n",
    "dup_part = dp[dp['new_index'].isin(vid_tableid_gruop_dup_list)]\n",
    "dup_part = dup_part.sort_values(['vid','table_id'])\n",
    "unique_part = dp[~dp['new_index'].isin(vid_tableid_gruop_dup_list)]\n",
    "\n",
    "# 仅对重复项目进行拼接操作 \n",
    "dp_dup = dup_part.groupby(['vid', 'table_id'], as_index=False).apply(merge_data).reset_index() # 重复体检项目合并结果\n",
    "dp_dup.rename(columns={0:'field_results'}, inplace=True)\n",
    "\n",
    "dp_dup = pd.concat([dp_dup, unique_part[['vid', 'table_id', 'field_results']]])\n",
    "print (\"---------END-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp_fmt = dp_dup.set_index(['vid', 'table_id']).unstack(fill_value=None) # 将同一个vid所有项目转换成整行\n",
    "dp_fmt.columns = dp_fmt.columns.droplevel(level=0)  # 删除cols的第一索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57298, 2795)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_fmt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp_fmt.to_csv('../Output/0504/data_yuchuli.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上为数据初处理：\n",
    "    将所有记录转换成以vid为主键，table_id为字段的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "——————————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dp_fmt = pd.read_csv(\"../Output/0504/data_yuchuli.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57298, 2796)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_fmt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字段筛选，缺失值占XX%以上的字段舍弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remainFeat(data, thread=0.9, exclude_cols=['0101', '0102', '0104', '0120', '0121','0125','0130','0131',\n",
    "                                               '0409','0413', '0424','0434', '0437', '0441', '0449','0438',\n",
    "                                               '1316','1330','1334','3402','3401',\n",
    "                                               'A301','A705','A801','B701']):\n",
    "    drop_cols = []\n",
    "    num_cols = int(data.shape[0])\n",
    "    for c in data.columns:\n",
    "        if c not in exclude_cols:\n",
    "            num_nan = data[c].isnull().sum()\n",
    "            if num_nan == 0:\n",
    "                continue\n",
    "            if (num_nan / num_cols) > thread:\n",
    "                drop_cols.append(c)\n",
    "    remain_feat = [c for c in data.columns if c not in drop_cols]\n",
    "    return remain_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = remainFeat(dp_fmt, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp_fmt = dp_fmt[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57298, 394)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_fmt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp_fmt.to_csv('../Output/0504/data_tezheng1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上为数据再处理：\n",
    "    由于数据中 体检项目的量较大，故2795个字段数量略长，而且其中很多很多字段大部分都是NAN，故舍弃，不考虑进来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "——————————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dp_fmt = pd.read_csv(\"../Output/0504/data_tezheng1.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/meinian_round1_train_20180408.csv\", encoding='gbk')\n",
    "test_df = pd.read_csv(\"../data/meinian_round1_test_b_20180505.csv\", encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57298, 394)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_fmt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dp_fmt = dp_fmt.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train_df, dp_fmt, on='vid', how='left')\n",
    "test = pd.merge(test_df, dp_fmt, on='vid', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 清洗train的目标指标   \n",
    "\n",
    "收缩压、舒张压、血清甘油三酯、血清高密度脂蛋白、血清低密度脂蛋白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanLabelForDigit(label):\n",
    "    x = str(label)\n",
    "    if '弃查' in x or '未查' in x:\n",
    "        return np.nan\n",
    "    elif len(x)>3:\n",
    "        return x[:3]\n",
    "    return x\n",
    "\n",
    "def cleanLabelForNotDigit(label):\n",
    "    import re\n",
    "    p = re.compile('\\d+\\.?\\d*')\n",
    "    x = str(label)\n",
    "    if '弃查' in x or '未查' in x:\n",
    "        return np.nan\n",
    "    elif x.count('.') >= 2: # 2.2.8\n",
    "        idx = x.index('.')+1\n",
    "        return (x[:idx]+x[idx:].replace('.', ''))\n",
    "    elif len(x)>16:  # 4.019999999999999\n",
    "        return x[0:6]\n",
    "    else:   # 16.04++   > 11.00   7.75轻度\n",
    "        return p.findall(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in ['收缩压','舒张压','血清甘油三酯','血清高密度脂蛋白','血清低密度脂蛋白']:\n",
    "    if c == '收缩压' or c == '舒张压':\n",
    "        train[c] = train[c].apply(cleanLabelForDigit)\n",
    "        train[c]=train[c].astype('float64')\n",
    "    else:\n",
    "        train[c] = train[c].apply(cleanLabelForNotDigit)\n",
    "        train[c]=train[c].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('../Output/0505/train_data_tezheng1.csv', index=False, encoding='utf-8')\n",
    "test.to_csv('../Output/0505/test_data_tezheng1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "——————————————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
